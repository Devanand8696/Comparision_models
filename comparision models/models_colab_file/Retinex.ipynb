{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMFpHOfBM/bU34wCcqgs5EY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mQ4fg2b9aj9V","executionInfo":{"status":"ok","timestamp":1704649432813,"user_tz":-330,"elapsed":29070,"user":{"displayName":"Devanand C M","userId":"10845017674034799015"}},"outputId":"f359e258-233e-4f8c-b346-36b707cd0300"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n"]},{"cell_type":"code","source":["import os\n","os.chdir('/content/gdrive/MyDrive/Retinexformer-master')\n"],"metadata":{"id":"YH_XJ9YGWc88","executionInfo":{"status":"ok","timestamp":1704649432813,"user_tz":-330,"elapsed":7,"user":{"displayName":"Devanand C M","userId":"10845017674034799015"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Retinexformer: One-stage Retinex-based Transformer for Low-light Image Enhancement\n","# Yuanhao Cai, Hao Bian, Jing Lin, Haoqian Wang, Radu Timofte, Yulun Zhang\n","# International Conference on Computer Vision (ICCV), 2023\n","# https://arxiv.org/abs/2303.06705\n","# https://github.com/caiyuanhao1998/Retinexformer\n","\n","import numpy as np\n","import os\n","import cv2\n","import math\n","from pdb import set_trace as stx\n","\n","\n","def calculate_psnr(img1, img2, border=0):\n","    # img1 and img2 have range [0, 255]\n","    #img1 = img1.squeeze()\n","    #img2 = img2.squeeze()\n","    if not img1.shape == img2.shape:\n","        raise ValueError('Input images must have the same dimensions.')\n","    h, w = img1.shape[:2]\n","    img1 = img1[border:h - border, border:w - border]\n","    img2 = img2[border:h - border, border:w - border]\n","\n","    img1 = img1.astype(np.float64)\n","    img2 = img2.astype(np.float64)\n","    mse = np.mean((img1 - img2)**2)\n","    if mse == 0:\n","        return float('inf')\n","    return 20 * math.log10(255.0 / math.sqrt(mse))\n","\n","\n","def PSNR(img1, img2):\n","    mse_ = np.mean((img1 - img2) ** 2)\n","    if mse_ == 0:\n","        return 100\n","    return 10 * math.log10(1 / mse_)\n","\n","\n","# --------------------------------------------\n","# SSIM\n","# --------------------------------------------\n","def ssim(img1, img2):\n","    C1 = (0.01 * 255)**2\n","    C2 = (0.03 * 255)**2\n","\n","    img1 = img1.astype(np.float64)\n","    img2 = img2.astype(np.float64)\n","    kernel = cv2.getGaussianKernel(11, 1.5)\n","    window = np.outer(kernel, kernel.transpose())\n","\n","    mu1 = cv2.filter2D(img1, -1, window)[5:-5, 5:-5]  # valid\n","    mu2 = cv2.filter2D(img2, -1, window)[5:-5, 5:-5]\n","    mu1_sq = mu1**2\n","    mu2_sq = mu2**2\n","    mu1_mu2 = mu1 * mu2\n","    sigma1_sq = cv2.filter2D(img1**2, -1, window)[5:-5, 5:-5] - mu1_sq\n","    sigma2_sq = cv2.filter2D(img2**2, -1, window)[5:-5, 5:-5] - mu2_sq\n","    sigma12 = cv2.filter2D(img1 * img2, -1, window)[5:-5, 5:-5] - mu1_mu2\n","\n","    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) *\n","                                                            (sigma1_sq + sigma2_sq + C2))\n","    return ssim_map.mean()\n","\n","def calculate_ssim(img1, img2, border=0):\n","    '''calculate SSIM\n","    the same outputs as MATLAB's\n","    img1, img2: [0, 255]\n","    '''\n","    #img1 = img1.squeeze()\n","    #img2 = img2.squeeze()\n","    if not img1.shape == img2.shape:\n","        raise ValueError('Input images must have the same dimensions.')\n","    h, w = img1.shape[:2]\n","    img1 = img1[border:h - border, border:w - border]\n","    img2 = img2[border:h - border, border:w - border]\n","\n","    if img1.ndim == 2:\n","        return ssim(img1, img2)\n","    elif img1.ndim == 3:\n","        if img1.shape[2] == 3:\n","            ssims = []\n","            for i in range(3):\n","                ssims.append(ssim(img1[:, :, i], img2[:, :, i]))\n","            return np.array(ssims).mean()\n","        elif img1.shape[2] == 1:\n","            return ssim(np.squeeze(img1), np.squeeze(img2))\n","    else:\n","        raise ValueError('Wrong input image dimensions.')\n","\n","\n","\n","\n","def load_img(filepath):\n","    return cv2.cvtColor(cv2.imread(filepath), cv2.COLOR_BGR2RGB)\n","\n","\n","def save_img(filepath, img):\n","    cv2.imwrite(filepath, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n","\n","\n","def load_gray_img(filepath):\n","    return np.expand_dims(cv2.imread(filepath, cv2.IMREAD_GRAYSCALE), axis=2)\n","\n","\n","def save_gray_img(filepath, img):\n","    cv2.imwrite(filepath, img)\n","\n","\n","def visualization(feature, save_path, type='max', colormap=cv2.COLORMAP_JET):\n","    '''\n","    :param feature: [C,H,W]\n","    :param save_path: saving path\n","    :param type: 'mean' or 'max'\n","    :param colormap: the type of the pseudocolor map\n","    '''\n","    feature = feature.cpu().numpy()\n","    if type == 'mean':\n","        feature = np.mean(feature, axis=0)\n","    else:\n","        feature = np.max(feature, axis=0)\n","    normed_feat = (feature - feature.min()) / (feature.max() - feature.min())\n","    normed_feat = (normed_feat * 255).astype('uint8')\n","    color_feat = cv2.applyColorMap(normed_feat, colormap)\n","    # stx()\n","    cv2.imwrite(save_path, color_feat)"],"metadata":{"id":"lFTOHAkgW3H-","executionInfo":{"status":"ok","timestamp":1704649455394,"user_tz":-330,"elapsed":982,"user":{"displayName":"Devanand C M","userId":"10845017674034799015"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["!pip install lmdb\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lg6VAyBJMpoQ","executionInfo":{"status":"ok","timestamp":1704649441160,"user_tz":-330,"elapsed":8353,"user":{"displayName":"Devanand C M","userId":"10845017674034799015"}},"outputId":"333f27e9-e36c-4f4d-d1f6-83970e64d6bc"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting lmdb\n","  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/299.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/299.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lmdb\n","Successfully installed lmdb-1.4.1\n"]}]},{"cell_type":"code","source":["!pip install einops\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7cDm8QlLNyNZ","executionInfo":{"status":"ok","timestamp":1704649446652,"user_tz":-330,"elapsed":5503,"user":{"displayName":"Devanand C M","userId":"10845017674034799015"}},"outputId":"da66843e-07a8-4125-e969-67aa98d7bcdb"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting einops\n","  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: einops\n","Successfully installed einops-0.7.0\n"]}]},{"cell_type":"code","source":["import importlib\n","from os import path as osp\n","\n","from basicsr.utils import get_root_logger, scandir\n","\n","# automatically scan and import model modules\n","# scan all the files under the 'models' folder and collect files ending with\n","# '_model.py'\n","model_folder = \"/content/gdrive/MyDrive/Retinexformer-master/basicsr/models\"\n","model_filenames = [\n","    osp.splitext(osp.basename(v))[0] for v in scandir(model_folder)\n","    if v.endswith('_model.py')\n","]\n","# import all the model modules\n","_model_modules = [\n","   importlib.import_module(f'basicsr.models.{file_name}')\n","   for file_name in model_filenames]\n","\n","\n","def create_model(opt):\n","    \"\"\"Create model.\n","\n","    Args:\n","        opt (dict): Configuration. It constains:\n","            model_type (str): Model type.\n","    \"\"\"\n","    model_type = opt['model_type']\n","\n","    # dynamic instantiation\n","    for module in _model_modules:\n","        model_cls = getattr(module, model_type, None)\n","        if model_cls is not None:\n","            break\n","    if model_cls is None:\n","        raise ValueError(f'Model {model_type} is not found.')\n","\n","    model = model_cls(opt)\n","\n","    logger = get_root_logger()\n","    logger.info(f'Model [{model.__class__.__name__}] is created.')\n","    return model\n"],"metadata":{"id":"1Dg_hrXmY7XX","executionInfo":{"status":"ok","timestamp":1704649489517,"user_tz":-330,"elapsed":30872,"user":{"displayName":"Devanand C M","userId":"10845017674034799015"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import yaml\n","from collections import OrderedDict\n","from os import path as osp\n","\n","\n","def ordered_yaml():\n","    \"\"\"Support OrderedDict for yaml.\n","\n","    Returns:\n","        yaml Loader and Dumper.\n","    \"\"\"\n","    try:\n","        from yaml import CDumper as Dumper\n","        from yaml import CLoader as Loader\n","    except ImportError:\n","        from yaml import Dumper, Loader\n","\n","    _mapping_tag = yaml.resolver.BaseResolver.DEFAULT_MAPPING_TAG\n","\n","    def dict_representer(dumper, data):\n","        return dumper.represent_dict(data.items())\n","\n","    def dict_constructor(loader, node):\n","        return OrderedDict(loader.construct_pairs(node))\n","\n","    Dumper.add_representer(OrderedDict, dict_representer)\n","    Loader.add_constructor(_mapping_tag, dict_constructor)\n","    return Loader, Dumper\n","\n","\n","def parse(opt_path, is_train=True):\n","    \"\"\"Parse option file.\n","\n","    Args:\n","        opt_path (str): Option file path.\n","        is_train (str): Indicate whether in training or not. Default: True.\n","\n","    Returns:\n","        (dict): Options.\n","    \"\"\"\n","    with open(opt_path, mode='r') as f:\n","        Loader, _ = ordered_yaml()\n","        opt = yaml.load(f, Loader=Loader)\n","\n","    opt['is_train'] = is_train\n","\n","    opt['name'] = osp.basename(opt_path).split('.')[0]  # 获取文件名\n","    # datasets\n","    for phase, dataset in opt['datasets'].items():\n","        # for several datasets, e.g., test_1, test_2\n","        phase = phase.split('_')[0]\n","        dataset['phase'] = phase\n","        if 'scale' in opt:\n","            dataset['scale'] = opt['scale']\n","        if dataset.get('dataroot_gt') is not None:\n","            dataset['dataroot_gt'] = osp.expanduser(dataset['dataroot_gt'])\n","        if dataset.get('dataroot_lq') is not None:\n","            dataset['dataroot_lq'] = osp.expanduser(dataset['dataroot_lq'])\n","\n","    # paths\n","    for key, val in opt['path'].items():\n","        if (val is not None) and ('resume_state' in key\n","                                  or 'pretrain_network' in key):\n","            opt['path'][key] = osp.expanduser(val)\n","    opt['path']['root'] = osp.abspath(\n","        osp.join(\"/content/gdrive/MyDrive/Retinexformer-master/basicsr/utils/options.py\", osp.pardir, osp.pardir, osp.pardir))\n","    if is_train:\n","        experiments_root = osp.join(opt['path']['root'], 'experiments',\n","                                    opt['name'])\n","        opt['path']['experiments_root'] = experiments_root\n","        opt['path']['models'] = osp.join(experiments_root, 'models')\n","        opt['path']['training_states'] = osp.join(experiments_root,\n","                                                  'training_states')\n","        opt['path']['log'] = experiments_root\n","        opt['path']['visualization'] = osp.join(experiments_root,\n","                                                'visualization')\n","\n","        # change some options for debug mode\n","        if 'debug' in opt['name']:\n","            if 'val' in opt:\n","                opt['val']['val_freq'] = 8\n","            opt['logger']['print_freq'] = 1\n","            opt['logger']['save_checkpoint_freq'] = 8\n","    else:  # test\n","        results_root = osp.join(opt['path']['root'], 'results', opt['name'])\n","        opt['path']['results_root'] = results_root\n","        opt['path']['log'] = results_root\n","        opt['path']['visualization'] = osp.join(results_root, 'visualization')\n","\n","    return opt\n","\n","\n","def dict2str(opt, indent_level=1):\n","    \"\"\"dict to string for printing options.\n","\n","    Args:\n","        opt (dict): Option dict.\n","        indent_level (int): Indent level. Default: 1.\n","\n","    Return:\n","        (str): Option string for printing.\n","    \"\"\"\n","    msg = '\\n'\n","    for k, v in opt.items():\n","        if isinstance(v, dict):\n","            msg += ' ' * (indent_level * 2) + k + ':['\n","            msg += dict2str(v, indent_level + 1)\n","            msg += ' ' * (indent_level * 2) + ']\\n'\n","        else:\n","            msg += ' ' * (indent_level * 2) + k + ': ' + str(v) + '\\n'\n","    return msg\n"],"metadata":{"id":"qXxYIl3vc9kG","executionInfo":{"status":"ok","timestamp":1704649489517,"user_tz":-330,"elapsed":11,"user":{"displayName":"Devanand C M","userId":"10845017674034799015"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Retinexformer: One-stage Retinex-based Transformer for Low-light Image Enhancement\n","# Yuanhao Cai, Hao Bian, Jing Lin, Haoqian Wang, Radu Timofte, Yulun Zhang\n","# International Conference on Computer Vision (ICCV), 2023\n","# https://arxiv.org/abs/2303.06705\n","# https://github.com/caiyuanhao1998/Retinexformer\n","\n","from ast import arg\n","import numpy as np\n","import os\n","import argparse\n","from tqdm import tqdm\n","\n","import torch.nn as nn\n","import torch\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","#import utils\n","\n","from natsort import natsorted\n","from glob import glob\n","from skimage import img_as_ubyte\n","from pdb import set_trace as stx\n","from skimage import metrics\n","\n","#from basicsr.models import  create_model\n","#from basicsr.utils.options import dict2str, parse\n","\n","\n","\n","class DotDict:\n","    def __init__(self, dictionary):\n","        self.__dict__.update(dictionary)\n","\n","# Define the arguments using a dictionary\n","args_dict = {\n","    'input_dir': '/content/gdrive/MyDrive/model_datasets/DICM',\n","    'result_dir': './results/',\n","    'opt': '/content/gdrive/MyDrive/Retinexformer-master/Options/RetinexFormer_LOL_v1.yml',\n","    'weights': '/content/gdrive/MyDrive/Retinexformer-master/Trained_model/LOL_v1.pth',\n","    'dataset': 'lol',\n","    'gpus': '0'\n","}\n","\n","# Create a DotDict instance\n","args = DotDict(args_dict)\n","\n","\n","\n","# 指定 gpu\n","#gpu_list = ','.join(str(x) for x in args.gpus)\n","#os.environ['CUDA_VISIBLE_DEVICES'] = gpu_list\n","#print('export CUDA_VISIBLE_DEVICES=' + gpu_list)\n","\n","####### Load yaml #######\n","yaml_file = args.opt\n","weights = args.weights\n","print(f\"dataset {args.dataset}\")\n","\n","import yaml\n","\n","try:\n","    from yaml import CLoader as Loader\n","except ImportError:\n","    from yaml import Loader\n","\n","opt = parse(args.opt, is_train=False)\n","opt['dist'] = False\n","\n","\n","x = yaml.load(open(args.opt, mode='r'), Loader=Loader)\n","s = x['network_g'].pop('type')\n","##########################\n","\n","\n","model_restoration = create_model(opt).net_g\n","\n","# 加载模型\n","checkpoint = torch.load(weights)\n","\n","try:\n","    model_restoration.load_state_dict(checkpoint['params'])\n","except:\n","    new_checkpoint = {}\n","    for k in checkpoint['params']:\n","        new_checkpoint['module.' + k] = checkpoint['params'][k]\n","    model_restoration.load_state_dict(new_checkpoint)\n","\n","print(\"===>Testing using weights: \", weights)\n","model_restoration.cuda()\n","model_restoration = nn.DataParallel(model_restoration)\n","model_restoration.eval()\n","\n","# 生成输出结果的文件\n","factor = 4\n","dataset = args.dataset\n","config = os.path.basename(args.opt).split('.')[0]\n","checkpoint_name = os.path.basename(args.weights).split('.')[0]\n","result_dir = os.path.join(args.result_dir, dataset, config, checkpoint_name)\n","result_dir_input = os.path.join(args.result_dir, dataset, 'input')\n","result_dir_gt = os.path.join(args.result_dir, dataset, 'gt')\n","# stx()\n","os.makedirs(result_dir, exist_ok=True)\n","\n","psnr = []\n","ssim_v = []\n","if dataset in ['SID', 'SMID', 'SDSD_indoor', 'SDSD_outdoor']:\n","    os.makedirs(result_dir_input, exist_ok=True)\n","    os.makedirs(result_dir_gt, exist_ok=True)\n","    if dataset == 'SID':\n","        from basicsr.data.SID_image_dataset import Dataset_SIDImage as Dataset\n","    elif dataset == 'SMID':\n","        from basicsr.data.SMID_image_dataset import Dataset_SMIDImage as Dataset\n","    else:\n","        from basicsr.data.SDSD_image_dataset import Dataset_SDSDImage as Dataset\n","    opt = opt['datasets']['val']\n","    opt['phase'] = 'test'\n","    if opt.get('scale') is None:\n","        opt['scale'] = 1\n","    if '~' in opt['dataroot_gt']:\n","        opt['dataroot_gt'] = os.path.expanduser('~') + opt['dataroot_gt'][1:]\n","    if '~' in opt['dataroot_lq']:\n","        opt['dataroot_lq'] = os.path.expanduser('~') + opt['dataroot_lq'][1:]\n","    dataset = Dataset(opt)\n","    print(f'test dataset length: {len(dataset)}')\n","    dataloader = DataLoader(dataset=dataset, batch_size=1, shuffle=False)\n","    with torch.inference_mode():\n","        for data_batch in tqdm(dataloader):\n","            torch.cuda.ipc_collect()\n","            torch.cuda.empty_cache()\n","\n","            input_ = data_batch['lq']\n","            input_save = data_batch['lq'].cpu().permute(\n","                0, 2, 3, 1).squeeze(0).numpy()\n","            target = data_batch['gt'].cpu().permute(\n","                0, 2, 3, 1).squeeze(0).numpy()\n","            inp_path = data_batch['lq_path'][0]\n","\n","            # Padding in case images are not multiples of 4\n","            h, w = input_.shape[2], input_.shape[3]\n","            H, W = ((h + factor) // factor) * \\\n","                factor, ((w + factor) // factor) * factor\n","            padh = H - h if h % factor != 0 else 0\n","            padw = W - w if w % factor != 0 else 0\n","            input_ = F.pad(input_, (0, padw, 0, padh), 'reflect')\n","\n","            restored = model_restoration(input_)\n","\n","            # Unpad images to original dimensions\n","            restored = restored[:, :, :h, :w]\n","\n","            restored = torch.clamp(restored, 0, 1).cpu(\n","            ).detach().permute(0, 2, 3, 1).squeeze(0).numpy()\n","\n","            psnr.append(utils.PSNR(target, restored))\n","            ssim.append(utils.calculate_ssim(\n","                img_as_ubyte(target), img_as_ubyte(restored)))\n","            type_id = os.path.dirname(inp_path).split('/')[-1]\n","            os.makedirs(os.path.join(result_dir, type_id), exist_ok=True)\n","            os.makedirs(os.path.join(result_dir_input, type_id), exist_ok=True)\n","            os.makedirs(os.path.join(result_dir_gt, type_id), exist_ok=True)\n","            utils.save_img((os.path.join(result_dir, type_id, os.path.splitext(\n","                os.path.split(inp_path)[-1])[0] + '.png')), img_as_ubyte(restored))\n","            utils.save_img((os.path.join(result_dir_input, type_id, os.path.splitext(\n","                os.path.split(inp_path)[-1])[0] + '.png')), img_as_ubyte(input_save))\n","            utils.save_img((os.path.join(result_dir_gt, type_id, os.path.splitext(\n","                os.path.split(inp_path)[-1])[0] + '.png')), img_as_ubyte(target))\n","else:\n","\n","    input_dir = opt['datasets']['val']['dataroot_lq']\n","    target_dir = opt['datasets']['val']['dataroot_gt']\n","    print(input_dir)\n","    print(target_dir)\n","\n","    input_paths = natsorted(\n","        glob(os.path.join(input_dir, '*.png')) + glob(os.path.join(input_dir, '*.jpg')))\n","\n","    target_paths = natsorted(glob(os.path.join(\n","        target_dir, '*.png')) + glob(os.path.join(target_dir, '*.jpg')))\n","\n","    with torch.inference_mode():\n","        for inp_path, tar_path in tqdm(zip(input_paths, target_paths), total=len(target_paths)):\n","\n","            torch.cuda.ipc_collect()\n","            torch.cuda.empty_cache()\n","\n","            img = np.float32(load_img(inp_path)) / 255.\n","            target = np.float32(load_img(tar_path)) / 255.\n","\n","            img = torch.from_numpy(img).permute(2, 0, 1)\n","            input_ = img.unsqueeze(0).cuda()\n","\n","            # Padding in case images are not multiples of 4\n","            h, w = input_.shape[2], input_.shape[3]\n","            H, W = ((h + factor) // factor) * \\\n","                factor, ((w + factor) // factor) * factor\n","            padh = H - h if h % factor != 0 else 0\n","            padw = W - w if w % factor != 0 else 0\n","            input_ = F.pad(input_, (0, padw, 0, padh), 'reflect')\n","\n","            restored = model_restoration(input_)\n","\n","            # Unpad images to original dimensions\n","            restored = restored[:, :, :h, :w]\n","\n","            restored = torch.clamp(restored, 0, 1).cpu(\n","            ).detach().permute(0, 2, 3, 1).squeeze(0).numpy()\n","\n","            psnr.append(PSNR(target, restored))\n","            ssim_v.append(calculate_ssim( img_as_ubyte(target), img_as_ubyte(restored)))\n","           # print(result_dir)\n","            save_img((os.path.join(result_dir, os.path.splitext(os.path.split(inp_path)[-1])[0] + '.png')), img_as_ubyte(restored))\n","\n","psnr = np.mean(np.array(psnr))\n","ssim_v = np.mean(np.array(ssim_v))\n","print(\"PSNR: %f \" % (psnr))\n","print(\"SSIM: %f \" % (ssim_v))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZEaqNnzzWsHN","executionInfo":{"status":"ok","timestamp":1704650886280,"user_tz":-330,"elapsed":6905,"user":{"displayName":"Devanand C M","userId":"10845017674034799015"}},"outputId":"89c247ba-006c-4239-c11f-d6fcb2d8f12e"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["dataset lol\n","===>Testing using weights:  /content/gdrive/MyDrive/Retinexformer-master/Trained_model/LOL_v1.pth\n","//content/gdrive/MyDrive/model_datasets/U45\n","/content/gdrive/MyDrive/model_datasets/U45\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 45/45 [00:06<00:00,  7.18it/s]"]},{"output_type":"stream","name":"stdout","text":["PSNR: 13.726433 \n","SSIM: 0.532050 \n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["from ast import arg\n","import numpy as np\n","import os\n","import argparse\n","from tqdm import tqdm\n","\n","import torch.nn as nn\n","import torch\n","import torch.nn.functional as F\n","\n","from natsort import natsorted\n","from glob import glob\n","from skimage import img_as_ubyte\n","\n","class DotDict:\n","    def __init__(self, dictionary):\n","        self.__dict__.update(dictionary)\n","\n","# Define the arguments using a dictionary\n","args_dict = {\n","    'input_dir': '/content/gdrive/MyDrive/LOLdataset',\n","    'result_dir': './results/',\n","    'opt': '/content/gdrive/MyDrive/Retinexformer-master/Options/RetinexFormer_LOL_v1.yml',\n","    'weights': '/content/gdrive/MyDrive/Retinexformer-master/Trained_model/LOL_v1.pth',\n","    'gpus': '0'\n","}\n","\n","# Create a DotDict instance\n","args = DotDict(args_dict)\n","\n","# Load YAML configuration\n","yaml_file = args.opt\n","weights = args.weights\n","print(f\"dataset LOL\")\n","\n","import yaml\n","\n","try:\n","    from yaml import CLoader as Loader\n","except ImportError:\n","    from yaml import Loader\n","\n","opt = parse(args.opt, is_train=False)\n","opt['dist'] = False\n","\n","x = yaml.load(open(args.opt, mode='r'), Loader=Loader)\n","s = x['network_g'].pop('type')\n","\n","# Load model\n","model_restoration = create_model(opt).net_g\n","\n","# Load model weights\n","checkpoint = torch.load(weights)\n","\n","try:\n","    model_restoration.load_state_dict(checkpoint['params'])\n","except:\n","    new_checkpoint = {}\n","    for k in checkpoint['params']:\n","        new_checkpoint['module.' + k] = checkpoint['params'][k]\n","    model_restoration.load_state_dict(new_checkpoint)\n","\n","print(\"===> Testing using weights: \", weights)\n","model_restoration.cuda()\n","model_restoration = nn.DataParallel(model_restoration)\n","model_restoration.eval()\n","\n","# Set LOL dataset paths\n","input_dir = '/content/gdrive/MyDrive/LOLdataset/eval15/low'\n","result_dir = os.path.join(args.result_dir, 'LOL_results')\n","\n","os.makedirs(result_dir, exist_ok=True)\n","\n","psnr = []\n","ssim = []\n","\n","# Load LOL dataset\n","from basicsr.data.LOL_image_dataset import Dataset_LOLImage as Dataset\n","opt = opt['datasets']['val']\n","opt['phase'] = 'test'\n","if opt.get('scale') is None:\n","    opt['scale'] = 1\n","\n","dataset = Dataset(opt)\n","print(f'test dataset length: {len(dataset)}')\n","dataloader = DataLoader(dataset=dataset, batch_size=1, shuffle=False)\n","\n","with torch.inference_mode():\n","    for data_batch in tqdm(dataloader):\n","        torch.cuda.ipc_collect()\n","        torch.cuda.empty_cache()\n","\n","        input_ = data_batch['lq']\n","        input_save = data_batch['lq'].cpu().permute(\n","            0, 2, 3, 1).squeeze(0).numpy()\n","        target = data_batch['gt'].cpu().permute(\n","            0, 2, 3, 1).squeeze(0).numpy()\n","        inp_path = data_batch['lq_path'][0]\n","\n","        # Padding in case images are not multiples of 4\n","        factor = 4\n","        h, w = input_.shape[2], input_.shape[3]\n","        H, W = ((h + factor) // factor) * \\\n","            factor, ((w + factor) // factor) * factor\n","        padh = H - h if h % factor != 0 else 0\n","        padw = W - w if w % factor != 0 else 0\n","        input_ = F.pad(input_, (0, padw, 0, padh), 'reflect')\n","\n","        restored = model_restoration(input_)\n","\n","        # Unpad images to original dimensions\n","        restored = restored[:, :, :h, :w]\n","\n","        restored = torch.clamp(restored, 0, 1).cpu(\n","        ).detach().permute(0, 2, 3, 1).squeeze(0).numpy()\n","\n","        psnr.append(utils.PSNR(target, restored))\n","        ssim.append(utils.calculate_ssim(\n","            img_as_ubyte(target), img_as_ubyte(restored)))\n","\n","        type_id = os.path.dirname(inp_path).split('/')[-1]\n","        os.makedirs(os.path.join(result_dir, type_id), exist_ok=True)\n","        utils.save_img((os.path.join(result_dir, type_id, os.path.splitext(\n","            os.path.split(inp_path)[-1])[0] + '.png')), img_as_ubyte(restored))\n","        utils.save_img((os.path.join(result_dir_input, type_id, os.path.splitext(\n","            os.path.split(inp_path)[-1])[0] + '.png')), img_as_ubyte(input_save))\n","        utils.save_img((os.path.join(result_dir_gt, type_id, os.path.splitext(\n","            os.path.split(inp_path)[-1])[0] + '.png')), img_as_ubyte(target))\n","\n","# Calculate and print average PSNR and SSIM\n","psnr = np.mean(np.array(psnr))\n","ssim = np.mean(np.array(ssim))\n","print(\"PSNR: %f \" % (psnr))\n","print(\"SSIM: %f \" % (ssim))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"yy9tHbr1P0FH","executionInfo":{"status":"error","timestamp":1703747216255,"user_tz":-330,"elapsed":4976,"user":{"displayName":"Devanand C M","userId":"10845017674034799015"}},"outputId":"673affa3-3263-45a3-c1ea-70a88e122e10"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["dataset LOL\n","===> Testing using weights:  /content/gdrive/MyDrive/Retinexformer-master/Trained_model/LOL_v1.pth\n"]},{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-cc5fcc147345>\u001b[0m in \u001b[0;36m<cell line: 78>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m# Load LOL dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbasicsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOL_image_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset_LOLImage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'datasets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'phase'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'basicsr.data.LOL_image_dataset'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["!python   Enhancement/test_from_dataset.py --opt Options/RetinexFormer_LOL_v1.yml --weights pretrained_weights/LOL_v1.pth --dataset \"/content/gdrive/MyDrive/LOLdataset/eval15/low\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vvk4GSOOAsyM","executionInfo":{"status":"ok","timestamp":1703597995337,"user_tz":-330,"elapsed":4174,"user":{"displayName":"Devanand C M","userId":"10845017674034799015"}},"outputId":"6fb0a66f-b68f-4ce2-98e2-d2791bd7828e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["export CUDA_VISIBLE_DEVICES=0\n","dataset /content/gdrive/MyDrive/LOLdataset/eval15/low\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Retinexformer-master/Enhancement/test_from_dataset.py\", line 62, in <module>\n","    opt = parse_1(args.opt, is_train=False)\n","NameError: name 'parse_1' is not defined. Did you mean: 'parser'?\n"]}]}]}